{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import datetime\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what youâ€™re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_pq_urls():\n",
    "    response = requests.get(TAXI_URL)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "        results_page = BeautifulSoup(response.content,'lxml')\n",
    "        results_page\n",
    "        lists = results_page.find('div',{\"class\":\"faq-v1\"})\n",
    "        \n",
    "        a=lists.find_all('div',{\"class\":\"faq-answers\"})\n",
    "        #print(a)\n",
    "        trip_datalist=[]\n",
    "        for item in a:\n",
    "            #print(item)\n",
    "            h=item.find_all('a',{\"title\":\"Yellow Taxi Trip Records\"})\n",
    "            for link in h:\n",
    "                #print(link.get(\"href\"))\n",
    "                trip_datalist.append(link.get(\"href\"))\n",
    "        return trip_datalist\n",
    "    else:\n",
    "        print(\"Failure\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5224932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_taxi_pq_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34e6f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29311\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db1f9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((-74.18445 40.69500, -74.18449 40.695...</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.691831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...</td>\n",
       "      <td>-73.831299</td>\n",
       "      <td>40.616745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.84793 40.87134, -73.84725 40.870...</td>\n",
       "      <td>-73.847422</td>\n",
       "      <td>40.864474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.97177 40.72582, -73.97179 40.725...</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.723752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((-74.17422 40.56257, -74.17349 40.562...</td>\n",
       "      <td>-74.188484</td>\n",
       "      <td>40.552659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.85107 40.91037, -73.85207 40.909...</td>\n",
       "      <td>-73.852215</td>\n",
       "      <td>40.897932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.90175 40.76078, -73.90147 40.759...</td>\n",
       "      <td>-73.906306</td>\n",
       "      <td>40.744235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-74.01333 40.70503, -74.01327 40.704...</td>\n",
       "      <td>-74.013023</td>\n",
       "      <td>40.709139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.95219 40.77302, -73.95269 40.772...</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \\\n",
       "0              EWR  POLYGON ((-74.18445 40.69500, -74.18449 40.695...   \n",
       "1           Queens  MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...   \n",
       "2            Bronx  POLYGON ((-73.84793 40.87134, -73.84725 40.870...   \n",
       "3        Manhattan  POLYGON ((-73.97177 40.72582, -73.97179 40.725...   \n",
       "4    Staten Island  POLYGON ((-74.17422 40.56257, -74.17349 40.562...   \n",
       "..             ...                                                ...   \n",
       "258          Bronx  POLYGON ((-73.85107 40.91037, -73.85207 40.909...   \n",
       "259         Queens  POLYGON ((-73.90175 40.76078, -73.90147 40.759...   \n",
       "260      Manhattan  POLYGON ((-74.01333 40.70503, -74.01327 40.704...   \n",
       "261      Manhattan  MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...   \n",
       "262      Manhattan  POLYGON ((-73.95219 40.77302, -73.95269 40.772...   \n",
       "\n",
       "           lon        lat  \n",
       "0   -74.174000  40.691831  \n",
       "1   -73.831299  40.616745  \n",
       "2   -73.847422  40.864474  \n",
       "3   -73.976968  40.723752  \n",
       "4   -74.188484  40.552659  \n",
       "..         ...        ...  \n",
       "258 -73.852215  40.897932  \n",
       "259 -73.906306  40.744235  \n",
       "260 -74.013023  40.709139  \n",
       "261 -73.946510  40.775932  \n",
       "262 -73.951010  40.778766  \n",
       "\n",
       "[263 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefile = gpd.read_file(\"Desktop/CU/E4501/taxi_zones/taxi_zones.shp\")\n",
    "type(shapefile)\n",
    "\n",
    "shapefile=shapefile.to_crs(4326)# reproject the geodataframe to a geographic CRS\n",
    "\n",
    "shapefile[\"lon\"]=shapefile[\"geometry\"].apply(lambda m: m.centroid.x)\n",
    "shapefile[\"lat\"]= shapefile[\"geometry\"].apply(lambda m: m.centroid.y)\n",
    "xx=pd.DataFrame(shapefile)\n",
    "xx.at[56,\"LocationID\"]=57\n",
    "xx.at[103,\"LocationID\"]=104\n",
    "xx.at[104,\"LocationID\"]=105\n",
    "shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e03b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, dest_folder: str):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)  # create folder if it does not exist\n",
    "\n",
    "    filename = url.split('/')[-1].replace(\" \", \"_\")  # be careful with file names\n",
    "    file_path = os.path.join(dest_folder, filename)\n",
    "\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.ok:\n",
    "        print(\"saving to\", os.path.abspath(file_path))\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 8):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    f.flush()\n",
    "                    os.fsync(f.fileno())\n",
    "    else:  # HTTP status code 4XX/5XX\n",
    "        print(\"Download failed: status code {}\\n{}\".format(r.status_code, r.text))\n",
    "    return file_path,filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49d5b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon_from_ID(locID,shapefile):\n",
    "    if locID in range(1,264):\n",
    "        sp=pd.DataFrame(shapefile)\n",
    "        lat= sp[sp[\"LocationID\"]==locID][\"lat\"].values[0]\n",
    "        lon= sp[sp[\"LocationID\"]==locID][\"lon\"].values[0]\n",
    "    else:\n",
    "        lat= None\n",
    "        lon= None\n",
    "    return lat,lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "815e87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lat_lon(origin_data,filename):\n",
    "    origin_data=pd.DataFrame(origin_data)\n",
    "    if \"PULocationID\" in origin_data.columns:\n",
    "        try:\n",
    "            origin_data[\"PU_lat\"]=origin_data[\"PULocationID\"].apply(lambda x: get_lat_lon_from_ID(x,shapefile)[0])\n",
    "            origin_data[\"PU_lon\"]=origin_data[\"PULocationID\"].apply(lambda x: get_lat_lon_from_ID(x,shapefile)[1])\n",
    "            origin_data[\"DO_lat\"]=origin_data[\"DOLocationID\"].apply(lambda x: get_lat_lon_from_ID(x,shapefile)[0])\n",
    "            origin_data[\"DO_lon\"]=origin_data[\"DOLocationID\"].apply(lambda x: get_lat_lon_from_ID(x,shapefile)[1])\n",
    "        #origin_data.to_parquet(filename+\"lat_lon\")\n",
    "        except:\n",
    "            origin_data[\"PU_lat\"]=origin_data[\"PU_lon\"]=origin_data[\"DO_lat\"]=origin_data[\"DO_lon\"]=0\n",
    "        return origin_data\n",
    "    else:\n",
    "        return origin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a7620b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(renamed_data):\n",
    "    origin_data=renamed_data\n",
    "    origin_data = origin_data.reset_index()\n",
    "    if \"PU_lat\" in origin_data.columns:\n",
    "        remove_list=[]\n",
    "        for i in range(len(origin_data)):\n",
    "            if not((NEW_YORK_BOX_COORDS[0][0] <=origin_data.iloc[i][\"PU_lat\"]<= NEW_YORK_BOX_COORDS[1][0]) and (NEW_YORK_BOX_COORDS[0][1]<=origin_data.iloc[i][\"PU_lon\"]<= NEW_YORK_BOX_COORDS[1][1]) and (NEW_YORK_BOX_COORDS[0][0] <=origin_data.iloc[i][\"DO_lat\"]<= NEW_YORK_BOX_COORDS[1][0]) and (NEW_YORK_BOX_COORDS[0][1]<=origin_data.iloc[i][\"DO_lon\"]<=NEW_YORK_BOX_COORDS[1][1])):\n",
    "                print(\"OUT\",i,origin_data.iloc[i][\"PU_lat\"],origin_data.iloc[i][\"PU_lon\"])\n",
    "                remove_list.append(i)\n",
    "                print(\"remove\",i)\n",
    "            else:\n",
    "                continue\n",
    "        origin_data=origin_data.drop(remove_list,axis=0)\n",
    "        \n",
    "        return origin_data\n",
    "    else:\n",
    "        print(\"whattttt\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45b47604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_datetime(cleaned_data):\n",
    "    if \"vendor_name\" in cleaned_data.columns:\n",
    "        cleaned_data = cleaned_data.rename({'vendor_name': 'VendorID','Passenger_Count':'passenger_count','Trip_Distance':'trip_distance','Rate_Code':'RatecodeID','store_and_forward':'store_and_fwd_flag','Tip_Amt':'tip_amount','Fare_Amt':'fare_amount','Total_Amt':'total_amount','Trip_Pickup_DateTime': 'tpep_pickup_datetime', 'Trip_Dropoff_DateTime': 'tpep_dropoff_datetime','Start_Lat':'PU_lat','Start_Lon':'PU_lon','End_Lat':'DO_lat','End_Lon':'DO_lon'}, axis='columns')\n",
    "    if \"vendor_id\" in cleaned_data.columns:\n",
    "        cleaned_data = cleaned_data.rename({'vendor_id': 'VendorID','rate_code':'RatecodeID','pickup_datetime': 'tpep_pickup_datetime', 'dropoff_datetime': 'tpep_dropoff_datetime','pickup_latitude':'PU_lat','pickup_longitude':'PU_lon','dropoff_latitude':'DO_lat','dropoff_longitude':'DO_lon'}, axis='columns')\n",
    "    return cleaned_data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c9431ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_months(renamed_data):\n",
    "    renamed_data[\"year\"]=renamed_data[\"tpep_pickup_datetime\"].apply(lambda x: datetime.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\").year )\n",
    "    renamed_data[\"month\"]=renamed_data[\"tpep_pickup_datetime\"].apply(lambda x: datetime.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\").month )\n",
    "    renamed_data[\"day\"]=renamed_data[\"tpep_pickup_datetime\"].apply(lambda x: datetime.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\").day )\n",
    "    renamed_data[\"hour\"]=renamed_data[\"tpep_pickup_datetime\"].apply(lambda x: datetime.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\").hour )\n",
    "    \n",
    "    return renamed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c79b4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def drop_columns(df):\n",
    "#    df = df.drop('column_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ff5d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(taxi_data):\n",
    "    taxi_data = taxi_data.rename({'tpep_pickup_datetime': 'pickup_datetime', 'tpep_dropoff_datetime': 'dropoff_datetime','PU_lat':'pickup_latitude','PU_lon':'pickup_longitude','DO_lat':'dropoff_latitude','DO_lon':'dropoff_longitude','trip_distance':'distance','tip_amount':'tip'}, axis='columns')\n",
    "    final = taxi_data[['year','month','hour','pickup_datetime','dropoff_datetime','pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','distance','tip','passenger_count']]\n",
    "    final.reset_index(drop=True, inplace=True)\n",
    "    print(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    all_pq_urls = find_taxi_pq_urls()\n",
    "    ii=0\n",
    "    for pq_url in all_pq_urls:\n",
    "        print(pq_url)\n",
    "        file_path, filename = download(pq_url,\"OriginalTaxiData\")\n",
    "        print(file_path,filename)\n",
    "        yearly_data = pd.read_parquet(file_path, engine='auto').sample(n=1250)\n",
    "        lat_lon_data = set_lat_lon(yearly_data,filename)\n",
    "        \n",
    "        renamed_data = rename_datetime(lat_lon_data)\n",
    "        cleaned_data = clean_data(renamed_data)##data with lat and lon and within the box\n",
    "\n",
    "        clean_month_taxi_data = set_months(cleaned_data)\n",
    "        \n",
    "        selected_data = select_columns(clean_month_taxi_data)\n",
    "        n=\"Downloads/1208/AllTaxi\"+filename+\".csv\"\n",
    "        selected_data.to_csv(n)\n",
    "        ii=ii+1 \n",
    "        all_taxi_dataframes.append(clean_month_taxi_data)    \n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    selected_columns_taxi_data = select_columns(taxi_data)\n",
    "    return selected_columns_taxi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b2396ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\n",
      "saving to C:\\Users\\29311\\OriginalTaxiData\\yellow_tripdata_2022-01.parquet\n",
      "OriginalTaxiData\\yellow_tripdata_2022-01.parquet yellow_tripdata_2022-01.parquet\n",
      "OUT 21 nan nan\n",
      "remove 21\n",
      "OUT 58 nan nan\n",
      "remove 58\n",
      "OUT 84 40.74033744175701 -73.99045782354732\n",
      "remove 84\n",
      "OUT 133 40.762252755319366 -73.98984464313301\n",
      "remove 133\n",
      "OUT 376 nan nan\n",
      "remove 376\n",
      "OUT 427 nan nan\n",
      "remove 427\n",
      "OUT 472 nan nan\n",
      "remove 472\n",
      "OUT 512 nan nan\n",
      "remove 512\n",
      "OUT 554 nan nan\n",
      "remove 554\n",
      "OUT 603 40.7147325069394 -73.98302455833488\n",
      "remove 603\n",
      "OUT 645 40.64698489239515 -73.78653298334973\n",
      "remove 645\n",
      "OUT 658 40.63790012347376 -73.9609682490637\n",
      "remove 658\n",
      "OUT 664 40.64698489239515 -73.78653298334973\n",
      "remove 664\n",
      "OUT 695 nan nan\n",
      "remove 695\n",
      "OUT 879 40.69454235438129 -73.83092407449995\n",
      "remove 879\n",
      "OUT 883 nan nan\n",
      "remove 883\n",
      "OUT 916 nan nan\n",
      "remove 916\n",
      "OUT 951 40.74991407790216 -73.97044256869235\n",
      "remove 951\n",
      "OUT 954 nan nan\n",
      "remove 954\n",
      "OUT 1036 nan nan\n",
      "remove 1036\n",
      "OUT 1083 nan nan\n",
      "remove 1083\n",
      "OUT 1166 nan nan\n",
      "remove 1166\n",
      "OUT 1181 40.64698489239515 -73.78653298334973\n",
      "remove 1181\n",
      "OUT 1197 nan nan\n",
      "remove 1197\n",
      "OUT 1232 nan nan\n",
      "remove 1232\n",
      "OUT 1249 nan nan\n",
      "remove 1249\n",
      "      year  month  hour     pickup_datetime    dropoff_datetime  \\\n",
      "0     2022      1     7 2022-01-11 07:27:36 2022-01-11 07:33:30   \n",
      "1     2022      1    12 2022-01-11 12:39:41 2022-01-11 12:49:04   \n",
      "2     2022      1    13 2022-01-27 13:16:28 2022-01-27 13:25:37   \n",
      "3     2022      1    11 2022-01-26 11:51:30 2022-01-26 12:07:04   \n",
      "4     2022      1     7 2022-01-26 07:52:09 2022-01-26 07:59:48   \n",
      "...    ...    ...   ...                 ...                 ...   \n",
      "1219  2022      1    21 2022-01-14 21:45:57 2022-01-14 21:56:01   \n",
      "1220  2022      1    14 2022-01-30 14:17:02 2022-01-30 14:35:19   \n",
      "1221  2022      1     9 2022-01-12 09:01:33 2022-01-12 09:05:21   \n",
      "1222  2022      1     0 2022-01-22 00:58:01 2022-01-22 01:07:48   \n",
      "1223  2022      1    21 2022-01-21 21:55:15 2022-01-21 22:00:53   \n",
      "\n",
      "      pickup_latitude  pickup_longitude  dropoff_latitude  dropoff_longitude  \\\n",
      "0           40.797962        -73.968168         40.790011         -73.945750   \n",
      "1           40.740439        -73.976495         40.764421         -73.977569   \n",
      "2           40.762253        -73.989845         40.783961         -73.978632   \n",
      "3           40.740439        -73.976495         40.756688         -73.972356   \n",
      "4           40.766948        -73.959635         40.766948         -73.959635   \n",
      "...               ...               ...               ...                ...   \n",
      "1219        40.782478        -73.965554         40.782478         -73.965554   \n",
      "1220        40.774376        -73.873629         40.754243         -73.934829   \n",
      "1221        40.740439        -73.976495         40.756729         -73.965146   \n",
      "1222        40.720889        -73.996919         40.748428         -73.999917   \n",
      "1223        40.783961        -73.978632         40.775965         -73.987646   \n",
      "\n",
      "      distance   tip  passenger_count  \n",
      "0         1.15  1.46              1.0  \n",
      "1         2.19  2.46              2.0  \n",
      "2         2.00  2.45              1.0  \n",
      "3         1.30  0.00              1.0  \n",
      "4         0.62  2.45              1.0  \n",
      "...        ...   ...              ...  \n",
      "1219      1.89  2.56              2.0  \n",
      "1220      4.50  0.00              1.0  \n",
      "1221      1.04  0.00              1.0  \n",
      "1222      2.03  2.56              1.0  \n",
      "1223      0.80  1.00              1.0  \n",
      "\n",
      "[1224 rows x 12 columns]\n",
      "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet\n",
      "saving to C:\\Users\\29311\\OriginalTaxiData\\yellow_tripdata_2022-02.parquet\n",
      "OriginalTaxiData\\yellow_tripdata_2022-02.parquet yellow_tripdata_2022-02.parquet\n",
      "OUT 27 nan nan\n",
      "remove 27\n",
      "OUT 58 nan nan\n",
      "remove 58\n",
      "OUT 87 nan nan\n",
      "remove 87\n",
      "OUT 128 nan nan\n",
      "remove 128\n",
      "OUT 232 nan nan\n",
      "remove 232\n",
      "OUT 252 40.765484087889845 -73.95473878380504\n",
      "remove 252\n",
      "OUT 360 nan nan\n",
      "remove 360\n",
      "OUT 397 nan nan\n",
      "remove 397\n",
      "OUT 417 40.64698489239515 -73.78653298334973\n",
      "remove 417\n",
      "OUT 428 40.78043643718997 -73.95701169835739\n",
      "remove 428\n",
      "OUT 459 40.64698489239515 -73.78653298334973\n",
      "remove 459\n",
      "OUT 536 nan nan\n",
      "remove 536\n",
      "OUT 555 nan nan\n",
      "remove 555\n",
      "OUT 573 nan nan\n",
      "remove 573\n",
      "OUT 652 nan nan\n",
      "remove 652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m taxi_data\u001b[38;5;241m=\u001b[39m\u001b[43mget_and_clean_taxi_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mget_and_clean_taxi_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m lat_lon_data \u001b[38;5;241m=\u001b[39m set_lat_lon(yearly_data,filename)\n\u001b[0;32m     12\u001b[0m renamed_data \u001b[38;5;241m=\u001b[39m rename_datetime(lat_lon_data)\n\u001b[1;32m---> 13\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenamed_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m##data with lat and lon and within the box\u001b[39;00m\n\u001b[0;32m     15\u001b[0m clean_month_taxi_data \u001b[38;5;241m=\u001b[39m set_months(cleaned_data)\n\u001b[0;32m     17\u001b[0m selected_data \u001b[38;5;241m=\u001b[39m select_columns(clean_month_taxi_data)\n",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36mclean_data\u001b[1;34m(renamed_data)\u001b[0m\n\u001b[0;32m      5\u001b[0m remove_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(origin_data)):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m((NEW_YORK_BOX_COORDS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39morigin_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPU_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m NEW_YORK_BOX_COORDS[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m (NEW_YORK_BOX_COORDS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43morigin_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPU_lon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m NEW_YORK_BOX_COORDS[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m (NEW_YORK_BOX_COORDS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39morigin_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDO_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m NEW_YORK_BOX_COORDS[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m (NEW_YORK_BOX_COORDS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39morigin_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDO_lon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mNEW_YORK_BOX_COORDS[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m,i,origin_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPU_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m],origin_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPU_lon\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m         remove_list\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1074\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1071\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1073\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1628\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m-> 1628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3714\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[0;32m   3713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3714\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3716\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[0;32m   3717\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1085\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(block, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m], [ref])\n\u001b[1;32m-> 1085\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43minterleaved_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1087\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# GH#46406\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:226\u001b[0m, in \u001b[0;36minterleaved_dtype\u001b[1;34m(dtypes)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dtypes):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_common_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1642\u001b[0m, in \u001b[0;36mfind_common_type\u001b[1;34m(types)\u001b[0m\n\u001b[0;32m   1639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(t) \u001b[38;5;129;01mor\u001b[39;00m is_float_dtype(t) \u001b[38;5;129;01mor\u001b[39;00m is_complex_dtype(t):\n\u001b[0;32m   1640\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_common_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numerictypes.py:652\u001b[0m, in \u001b[0;36mfind_common_type\u001b[1;34m(array_types, scalar_types)\u001b[0m\n\u001b[0;32m    649\u001b[0m array_types \u001b[38;5;241m=\u001b[39m [dtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m array_types]\n\u001b[0;32m    650\u001b[0m scalar_types \u001b[38;5;241m=\u001b[39m [dtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m scalar_types]\n\u001b[1;32m--> 652\u001b[0m maxa \u001b[38;5;241m=\u001b[39m \u001b[43m_can_coerce_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m maxsc \u001b[38;5;241m=\u001b[39m _can_coerce_all(scalar_types)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numerictypes.py:581\u001b[0m, in \u001b[0;36m_can_coerce_all\u001b[1;34m(dtypelist, start)\u001b[0m\n\u001b[0;32m    579\u001b[0m thisind \u001b[38;5;241m=\u001b[39m start\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m thisind \u001b[38;5;241m<\u001b[39m __len_test_types:\n\u001b[1;32m--> 581\u001b[0m     newdtype \u001b[38;5;241m=\u001b[39m \u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__test_types\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthisind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     numcoerce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dtypelist \u001b[38;5;28;01mif\u001b[39;00m newdtype \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m x])\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m numcoerce \u001b[38;5;241m==\u001b[39m N:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "taxi_data=get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70dcd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data#.reset_index()\n",
    "taxi_data.to_csv('Downloads/1208/------ALLLLLLLTaxi------.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da0581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\"TODO\"]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_N = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_N).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_N, \"some_descriptive_name.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
