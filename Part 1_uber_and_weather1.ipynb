{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "import bs4\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm #统计\n",
    "from statsmodels.tsa.stattools import adfuller #ADF检验\n",
    "import matplotlib as mpl #画图\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['font.family']='serif'\n",
    "plt.style.use('seaborn') \n",
    "\n",
    "perc=[0.01,0.05,0.25,0.5,0.75,0.9,0.95,0.99]\n",
    "def isid(data,variables): #重复\n",
    "    dup=data.duplicated(variables,keep=False)\n",
    "    if True in dup.values:\n",
    "        print(str(variables)+\" Do NOT uniquely identify this dataset\") \n",
    "    else:\n",
    "        print(str(variables)+\" uniquely identify this dataset\")\n",
    "import os #地址\n",
    "os.chdir('/Users/yw/Desktop/4501 Project') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc6f92",
   "metadata": {},
   "source": [
    "$distance=2rarcsin \\bigg(\\sqrt { sin^2 \\big( \\frac{\\phi_2-\\phi_1}{2} \\big) +cos \\phi_1 · cos\\phi_2  · sin^2 \\big( \\frac{\\lambda_2 - \\lambda_1}{2} \\big) } \\bigg) $\n",
    "\n",
    "$\\phi: \\text{latitude of points};\\  \\lambda: \\text{longtitude of points}; \\ r: \\text{radius of sphere}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e8b00",
   "metadata": {},
   "source": [
    "def calculate_distance(from_coord, to_coord): #input ([longtitude1,latitude1],[longtitude2,latitude2]) \n",
    "    r=6373 #Earth radius\n",
    "    \n",
    "    #use radians rather than degrees\n",
    "    longtitude1=math.radians(from_coord[0])\n",
    "    latitude1=math.radians(from_coord[1])\n",
    "    longtitude2=math.radians(to_coord[0])\n",
    "    latitude2=math.radians(to_coord[1])\n",
    "    \n",
    "    part1=(math.sin((latitude2-latitude1)/2))**2\n",
    "    part2=math.cos(latitude1)*math.cos(latitude2)*(math.sin((longtitude2-longtitude1)/2))**2\n",
    "    distance=2*r*math.asin(math.sqrt(part1+part2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c081fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_add_distance(data,length): #input dataframe:([longtitude1,latitude1],[longtitude2,latitude2]) \n",
    "    r=6373 #Earth radius\n",
    "    \n",
    "    #use radians rather than degrees\n",
    "    for i in range(length):\n",
    "        data.loc[i,'picklong']=math.radians(data.loc[i,'pickup_longitude'])\n",
    "        data.loc[i,'picklat']=math.radians(data.loc[i,'pickup_latitude'])\n",
    "        data.loc[i,'droplong']=math.radians(data.loc[i,'dropoff_longitude'])\n",
    "        data.loc[i,'droplat']=math.radians(data.loc[i,'dropoff_latitude'])\n",
    "    \n",
    "        data.loc[i,'distance']=2*r*math.asin(\n",
    "            math.sqrt((math.sin((data.loc[i,'droplat']-data.loc[i,'picklat'])/2))**2\n",
    "                  +math.cos(data.loc[i,'picklat'])*math.cos(data.loc[i,'droplat'])\n",
    "                      *(math.sin((data.loc[i,'droplong']-data.loc[i,'picklong'])/2))**2))\n",
    "    del data['picklong'],data['picklat'],data['droplong'],data['droplat']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_csv_urls():\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_csv_urls = find_taxi_csv_urls()\n",
    "    for csv_url in all_csv_url:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "1. Load data with pandas\n",
    "2. Clean the data: \n",
    "- Remove unnecessary columns\n",
    "- Remove invalid data points (missing data / wrong range)\n",
    "- Normalize column names\n",
    "- Remove trips that start and/or end outside the designated coordinate box (-74.242330, 40.560445); (-73.717047, 40.560445); (-74.242330, 40.908524); (-73.717047, 40.908524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638da8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         200000 non-null  int64  \n",
      " 1   key                200000 non-null  object \n",
      " 2   fare_amount        200000 non-null  float64\n",
      " 3   pickup_datetime    200000 non-null  object \n",
      " 4   pickup_longitude   200000 non-null  float64\n",
      " 5   pickup_latitude    200000 non-null  float64\n",
      " 6   dropoff_longitude  199999 non-null  float64\n",
      " 7   dropoff_latitude   199999 non-null  float64\n",
      " 8   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "uber=pd.read_csv('uber_rides_sample.csv')\n",
    "uber.info() #missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b814a9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>42598914</td>\n",
       "      <td>2012-10-28 10:49:00.00000053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>16382965</td>\n",
       "      <td>2014-03-14 01:09:00.0000008</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>27804658</td>\n",
       "      <td>2009-06-29 00:42:00.00000078</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>20259894</td>\n",
       "      <td>2015-05-20 14:56:25.0000004</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11951496</td>\n",
       "      <td>2010-05-15 04:08:00.00000076</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            key  fare_amount  \\\n",
       "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "...            ...                            ...          ...   \n",
       "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
       "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
       "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
       "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
       "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
       "\n",
       "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "...                         ...               ...              ...   \n",
       "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
       "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
       "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
       "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
       "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0              -73.999512         40.723217                1  \n",
       "1              -73.994710         40.750325                1  \n",
       "2              -73.962565         40.772647                1  \n",
       "3              -73.965316         40.803349                3  \n",
       "4              -73.973082         40.761247                5  \n",
       "...                   ...               ...              ...  \n",
       "199995         -73.986525         40.740297                1  \n",
       "199996         -74.006672         40.739620                1  \n",
       "199997         -73.858957         40.692588                2  \n",
       "199998         -73.983215         40.695415                1  \n",
       "199999         -73.985508         40.768793                1  \n",
       "\n",
       "[200000 rows x 9 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c925af70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>199999.000000</td>\n",
       "      <td>199999.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.771250e+07</td>\n",
       "      <td>11.359955</td>\n",
       "      <td>-72.527638</td>\n",
       "      <td>39.935885</td>\n",
       "      <td>-72.525292</td>\n",
       "      <td>39.923890</td>\n",
       "      <td>1.684535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.601382e+07</td>\n",
       "      <td>9.901776</td>\n",
       "      <td>11.437787</td>\n",
       "      <td>7.720539</td>\n",
       "      <td>13.117408</td>\n",
       "      <td>6.794829</td>\n",
       "      <td>1.385997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-1340.648410</td>\n",
       "      <td>-74.015515</td>\n",
       "      <td>-3356.666300</td>\n",
       "      <td>-881.985513</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>5.539115e+05</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>-74.014402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.015288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>2.723455e+06</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>-74.006838</td>\n",
       "      <td>40.701801</td>\n",
       "      <td>-74.007460</td>\n",
       "      <td>40.686410</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.382535e+07</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-73.992065</td>\n",
       "      <td>40.734796</td>\n",
       "      <td>-73.991407</td>\n",
       "      <td>40.733823</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.774550e+07</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.981823</td>\n",
       "      <td>40.752592</td>\n",
       "      <td>-73.980093</td>\n",
       "      <td>40.753042</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.155530e+07</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>-73.967154</td>\n",
       "      <td>40.767158</td>\n",
       "      <td>-73.963658</td>\n",
       "      <td>40.768001</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>4.989257e+07</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>-73.950785</td>\n",
       "      <td>40.779855</td>\n",
       "      <td>-73.945389</td>\n",
       "      <td>40.782680</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5.265728e+07</td>\n",
       "      <td>30.330000</td>\n",
       "      <td>-73.871200</td>\n",
       "      <td>40.787702</td>\n",
       "      <td>-73.874212</td>\n",
       "      <td>40.793744</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5.487708e+07</td>\n",
       "      <td>53.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.806606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.829479</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.542357e+07</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>57.418457</td>\n",
       "      <td>1644.421482</td>\n",
       "      <td>1153.572603</td>\n",
       "      <td>872.697628</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0    fare_amount  pickup_longitude  pickup_latitude  \\\n",
       "count  2.000000e+05  200000.000000     200000.000000    200000.000000   \n",
       "mean   2.771250e+07      11.359955        -72.527638        39.935885   \n",
       "std    1.601382e+07       9.901776         11.437787         7.720539   \n",
       "min    1.000000e+00     -52.000000      -1340.648410       -74.015515   \n",
       "1%     5.539115e+05       3.300000        -74.014402         0.000000   \n",
       "5%     2.723455e+06       4.100000        -74.006838        40.701801   \n",
       "25%    1.382535e+07       6.000000        -73.992065        40.734796   \n",
       "50%    2.774550e+07       8.500000        -73.981823        40.752592   \n",
       "75%    4.155530e+07      12.500000        -73.967154        40.767158   \n",
       "90%    4.989257e+07      20.500000        -73.950785        40.779855   \n",
       "95%    5.265728e+07      30.330000        -73.871200        40.787702   \n",
       "99%    5.487708e+07      53.300000          0.000000        40.806606   \n",
       "max    5.542357e+07     499.000000         57.418457      1644.421482   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "count      199999.000000     199999.000000    200000.000000  \n",
       "mean          -72.525292         39.923890         1.684535  \n",
       "std            13.117408          6.794829         1.385997  \n",
       "min         -3356.666300       -881.985513         0.000000  \n",
       "1%            -74.015288          0.000000         1.000000  \n",
       "5%            -74.007460         40.686410         1.000000  \n",
       "25%           -73.991407         40.733823         1.000000  \n",
       "50%           -73.980093         40.753042         1.000000  \n",
       "75%           -73.963658         40.768001         2.000000  \n",
       "90%           -73.945389         40.782680         4.000000  \n",
       "95%           -73.874212         40.793744         5.000000  \n",
       "99%             0.000000         40.829479         6.000000  \n",
       "max          1153.572603        872.697628       208.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber.describe(perc) \n",
    "#problem: longtitude and latitude range\n",
    "#passenger_count outliers\n",
    "#fare_amount 499 有待考察"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b7171",
   "metadata": {},
   "source": [
    "#invalid data - drop\n",
    "uber[ (uber.pickup_longitude<-180) | (uber.pickup_latitude>90) | \\\n",
    "     (uber.dropoff_longitude<-180) | (uber.dropoff_longitude>180) | \\\n",
    "     (uber.dropoff_latitude<-90)  | (uber.dropoff_latitude>90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27a8815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87946</th>\n",
       "      <td>32736015</td>\n",
       "      <td>2013-07-02 03:51:57.0000001</td>\n",
       "      <td>24.1</td>\n",
       "      <td>2013-07-02 03:51:57 UTC</td>\n",
       "      <td>-73.950581</td>\n",
       "      <td>40.779692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                          key  fare_amount  \\\n",
       "87946    32736015  2013-07-02 03:51:57.0000001         24.1   \n",
       "\n",
       "               pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "87946  2013-07-02 03:51:57 UTC        -73.950581        40.779692   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "87946                NaN               NaN                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber[uber.duplicated()==True] #no duplicated data\n",
    "uber[uber.dropoff_longitude.isnull()==True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc31772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         200000 non-null  int64  \n",
      " 1   key                200000 non-null  object \n",
      " 2   fare_amount        200000 non-null  float64\n",
      " 3   pickup_datetime    200000 non-null  object \n",
      " 4   pickup_longitude   200000 non-null  float64\n",
      " 5   pickup_latitude    200000 non-null  float64\n",
      " 6   dropoff_longitude  199999 non-null  float64\n",
      " 7   dropoff_latitude   199999 non-null  float64\n",
      " 8   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "uber.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(uber):\n",
    "    uber=uber.iloc[:,2:] #drop unnecessary columns: first column\n",
    "    uber.pickup_datetime=pd.to_datetime(uber.pickup_datetime) #proper data type\n",
    "    uber['pickup_datetime']=uber['pickup_datetime'].dt.tz_localize(None)\n",
    "    \n",
    "    uber=uber[uber.dropoff_longitude.isnull()!=True]  #drop missing value\n",
    "    uber['date']=pd.to_datetime(uber['pickup_datetime'].dt.date) #add y-m-d time\n",
    "    uber['week']=uber['date'].dt.dayofweek+1\n",
    "    uber=uber.sort_values('pickup_datetime').reset_index(drop=True) #sort\n",
    "    #uber=uber[uber['fare_amount']>200]#drop outliers, 99% = 53.3\n",
    "    uber=uber[uber['passenger_count']<7] #drop outlier: passenger_count=208\n",
    "    #Remove trips that start and/or end outside the designated coordinate box \n",
    "    # (40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    uber=uber[(uber.pickup_longitude>=-74.242330) & (uber.pickup_longitude<=-73.717047) \\\n",
    "         & (uber.pickup_latitude >=40.560445 ) & (uber.pickup_latitude <= 40.908524)]\n",
    "    uber=uber[(uber.dropoff_longitude>=-74.242330) & (uber.dropoff_longitude<=-73.717047) \\\n",
    "         & (uber.dropoff_latitude >=40.560445 ) & (uber.dropoff_latitude <= 40.908524)]\n",
    "    uber=uber.reset_index(drop=True)\n",
    "    return uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(uber)\n",
    "    uber_dataframe = calculate_and_add_distance(uber_dataframe,uber_dataframe.count()[0])\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56f703f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data=get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1295f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.to_csv('uber_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "1. load data\n",
    "2. separate daily data and hourly data with necessary columns, drop other columns\n",
    "3. clean data \n",
    "* data type: datetime\n",
    "* grouping\n",
    "* deal with inconsistent data: precipitation: T & s\n",
    "4. use hourly data to replenish missing daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "b7b7e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather09=pd.read_csv('2009_weather.csv',low_memory=False)\n",
    "weather10=pd.read_csv('2010_weather.csv',low_memory=False)\n",
    "weather11=pd.read_csv('2011_weather.csv',low_memory=False)\n",
    "weather12=pd.read_csv('2012_weather.csv',low_memory=False)\n",
    "weather13=pd.read_csv('2013_weather.csv',low_memory=False)\n",
    "weather14=pd.read_csv('2014_weather.csv',low_memory=False)\n",
    "weather15=pd.read_csv('2015_weather.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba9593",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "def clean_weather_data_daily(dataframe):\n",
    "    df=pd.merge(dataframe['DATE'],dataframe['DailyPrecipitation'],left_index=True,right_index=True)\n",
    "    df1=pd.merge(dataframe['DailyAverageWindSpeed'],dataframe['DailyPeakWindSpeed'],left_index=True,right_index=True)\n",
    "    df2=pd.merge(df,df1,left_index=True,right_index=True)\n",
    "    \n",
    "    df2=df2.rename(columns=str.lower)\n",
    "    df2['date']=pd.to_datetime(df2.date)\n",
    "    df2['t']=df2['date'].dt.date\n",
    "    df2['t']=pd.to_datetime(df2.t)\n",
    "    \n",
    "    res=pd.DataFrame(df2.groupby('t')['dailyaveragewindspeed'].last())\n",
    "    res['dailypeakwindspeed']=pd.DataFrame(df2.groupby('t')['dailypeakwindspeed'].last())\n",
    "    res['dailyprecipitation']=pd.DataFrame(df2.groupby('t')['dailyprecipitation'].last())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c95d1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def clean_weather_data_daily(dataframe):\n",
    "    df=pd.merge(dataframe['DATE'],dataframe['DailyPrecipitation'],left_index=True,right_index=True)\n",
    "    df1=pd.merge(dataframe['DailyAverageWindSpeed'],dataframe['DailyPeakWindSpeed'],left_index=True,right_index=True)\n",
    "    df2=pd.merge(df,df1,left_index=True,right_index=True)\n",
    "    \n",
    "    df2=df2.rename(columns=str.lower)\n",
    "    df2['date']=pd.to_datetime(df2.date)\n",
    "    df2['date']=df2['date'].dt.date\n",
    "    df2['date']=pd.to_datetime(df2.date)\n",
    "    \n",
    "    res=pd.DataFrame(df2.groupby('date')['dailyaveragewindspeed'].last())\n",
    "    res['dailypeakwindspeed']=pd.DataFrame(df2.groupby('date')['dailypeakwindspeed'].last())\n",
    "    res['dailyprecipitation']=pd.DataFrame(df2.groupby('date')['dailyprecipitation'].last())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "556924d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily09=clean_weather_data_daily(weather09)\n",
    "daily10=clean_weather_data_daily(weather10)\n",
    "daily11=clean_weather_data_daily(weather11)\n",
    "daily12=clean_weather_data_daily(weather12)\n",
    "daily13=clean_weather_data_daily(weather13)\n",
    "daily14=clean_weather_data_daily(weather14)\n",
    "daily15=clean_weather_data_daily(weather15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8ebb2800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dailyaveragewindspeed</th>\n",
       "      <th>dailypeakwindspeed</th>\n",
       "      <th>dailyprecipitation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dailyaveragewindspeed  dailypeakwindspeed dailyprecipitation\n",
       "date                                                                    \n",
       "2015-11-28                    NaN              2237.0               0.02\n",
       "2015-11-29                    NaN              2237.0               0.00"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily15[daily15['dailypeakwindspeed']>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather_data_hourly(dataframe):\n",
    "    \n",
    "    df=pd.merge(dataframe['DATE'],dataframe['HourlyWindGustSpeed'],left_index=True,right_index=True)\n",
    "    df1=pd.merge(dataframe['HourlyWindSpeed'],dataframe['DailySustainedWindSpeed'],left_index=True,right_index=True)\n",
    "    df2=pd.merge(df,df1,left_index=True,right_index=True)\n",
    "    df2['HourlyPrecipitation']=dataframe['HourlyPrecipitation']\n",
    "    \n",
    "    df2.loc[df2['HourlyPrecipitation']=='T','HourlyPrecipitation']=0 #把T微量降雨改成0\n",
    "    df2=df2.drop(df2[df2['HourlyPrecipitation'].str.contains(pat='s')==True].index) #数据含如1.2s这样的乱数据\n",
    "    df2['HourlyPrecipitation']=df2['HourlyPrecipitation'].astype(float) #改成float后面可以加在一起算daily precipitation\n",
    "    \n",
    "    df2=df2.rename(columns=str.lower)\n",
    "    df2['date']=pd.to_datetime(df2.date)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "85aacc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour09=clean_weather_data_hourly(weather09)\n",
    "hour10=clean_weather_data_hourly(weather10)\n",
    "hour11=clean_weather_data_hourly(weather11)\n",
    "hour12=clean_weather_data_hourly(weather12)\n",
    "hour13=clean_weather_data_hourly(weather13)\n",
    "hour14=clean_weather_data_hourly(weather14)\n",
    "hour15=clean_weather_data_hourly(weather15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b66385e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#给daily数据补充hourly数据generate的数据\n",
    "def adddata_daily(changedf,adddf):\n",
    "    \n",
    "    adddf['t']=adddf['date'].dt.date\n",
    "    adddf['t']=pd.to_datetime(adddf.t)\n",
    "    \n",
    "    changedf['averagehourlywindspeed']=adddf.groupby('t')['hourlywindspeed'].mean()\n",
    "    changedf['peakhourlywindspeed']=adddf.groupby('t')['hourlywindspeed'].max()\n",
    "    ##wind gust 不知道是否需要\n",
    "    changedf['averagehourlywindgustspeed']=adddf.groupby('t')['hourlywindgustspeed'].mean()\n",
    "    changedf['peakhourlywindgustspeed']=adddf.groupby('t')['hourlywindgustspeed'].max()\n",
    "    changedf['sumhourlyprecipitation']=adddf[adddf['hourlyprecipitation'].isnull()==False].groupby('t')['hourlyprecipitation'].sum()\n",
    "    \n",
    "    changedf.loc[changedf['dailyaveragewindspeed'].isnull()==True,'dailyaveragewindspeed']=changedf['averagehourlywindspeed']\n",
    "    changedf.loc[changedf['dailypeakwindspeed'].isnull()==True,'dailypeakwindspeed']=changedf['peakhourlywindspeed']\n",
    "    changedf.loc[changedf['dailyprecipitation'].isnull()==True,'dailyprecipitation']=changedf['sumhourlyprecipitation']\n",
    "    changedf=changedf.reset_index()\n",
    "    return changedf.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "26aa5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily09=adddata_daily(daily09,hour09)\n",
    "daily10=adddata_daily(daily10,hour10)\n",
    "daily11=adddata_daily(daily11,hour11)\n",
    "daily12=adddata_daily(daily12,hour12)\n",
    "daily13=adddata_daily(daily13,hour13)\n",
    "daily14=adddata_daily(daily14,hour14)\n",
    "daily15=adddata_daily(daily15,hour15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e178b3c",
   "metadata": {},
   "source": [
    "从daily generate hourly data怎么做呢\n",
    "\n",
    "但剩下还有些空缺值，是否需要删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "7710de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily=pd.concat([daily09,daily10,daily11,daily12,daily13,daily14,daily15])\n",
    "hour=pd.concat([hour09,hour10,hour11,hour12,hour13,hour14,hour15])\n",
    "del hour['t']\n",
    "hour=hour.reset_index(drop=True)\n",
    "daily=daily.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "08696ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dailyaveragewindspeed</th>\n",
       "      <th>dailypeakwindspeed</th>\n",
       "      <th>dailyprecipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>11.041667</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.806452</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>7.370370</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>6.925926</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2551 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  dailyaveragewindspeed  dailypeakwindspeed dailyprecipitation\n",
       "0    2009-01-01              11.041667                18.0                NaN\n",
       "1    2009-01-02               6.806452                16.0                0.0\n",
       "2    2009-01-03               9.875000                15.0                0.0\n",
       "3    2009-01-04               7.370370                10.0                NaN\n",
       "4    2009-01-05               6.925926                11.0                0.0\n",
       "...         ...                    ...                 ...                ...\n",
       "2546 2015-12-27               5.700000                26.0               0.12\n",
       "2547 2015-12-28               8.300000                28.0               0.03\n",
       "2548 2015-12-29               7.000000                24.0               0.45\n",
       "2549 2015-12-30               4.100000                13.0               0.19\n",
       "2550 2015-12-31               5.400000                20.0               0.03\n",
       "\n",
       "[2551 rows x 4 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\"TODO\"]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b00e7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour.to_csv('hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58e96010",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.to_csv('daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e9da5",
   "metadata": {},
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
